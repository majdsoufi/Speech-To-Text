{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supports 8 and 16 bit audio formats.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-2f9fc65e975d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0msignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadframes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnFrames\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnChannels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mspf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minterpret_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnFrames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnChannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mampWidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;31m# get window size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-2f9fc65e975d>\u001b[0m in \u001b[0;36minterpret_wav\u001b[1;34m(raw_bytes, n_frames, n_channels, sample_width, interleaved)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint16\u001b[0m \u001b[1;31m# signed 2-byte short\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only supports 8 and 16 bit audio formats.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mchannels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Only supports 8 and 16 bit audio formats."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import wave\n",
    "import sys\n",
    "import math\n",
    "import contextlib\n",
    "\n",
    "fname = 'perfect.wav.wav'\n",
    "outname = 'filtered.wav'\n",
    "\n",
    "cutOffFrequency = 400.0\n",
    "\n",
    "# from http://stackoverflow.com/questions/13728392/moving-average-or-running-mean\n",
    "def running_mean(x, windowSize):\n",
    "  cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "  return (cumsum[windowSize:] - cumsum[:-windowSize]) / windowSize\n",
    "\n",
    "# from http://stackoverflow.com/questions/2226853/interpreting-wav-data/2227174#2227174\n",
    "def interpret_wav(raw_bytes, n_frames, n_channels, sample_width, interleaved = True):\n",
    "\n",
    "    if sample_width == 1:\n",
    "        dtype = np.uint8 # unsigned char\n",
    "    elif sample_width == 0.5:\n",
    "        dtype = np.int16 # signed 2-byte short\n",
    "    else:\n",
    "        raise ValueError(\"Only supports 8 and 16 bit audio formats.\")\n",
    "\n",
    "    channels = np.fromstring(raw_bytes, dtype=dtype)\n",
    "\n",
    "    if interleaved:\n",
    "        # channels are interleaved, i.e. sample N of channel M follows sample N of channel M-1 in raw data\n",
    "        channels.shape = (n_frames, n_channels)\n",
    "        channels = channels.T\n",
    "    else:\n",
    "        # channels are not interleaved. All samples from channel M occur before all samples from channel M-1\n",
    "        channels.shape = (n_channels, n_frames)\n",
    "\n",
    "    return channels\n",
    "\n",
    "with contextlib.closing(wave.open(fname,'rb')) as spf:\n",
    "    sampleRate = spf.getframerate()\n",
    "    ampWidth = spf.getsampwidth()\n",
    "    nChannels = spf.getnchannels()\n",
    "    nFrames = spf.getnframes()\n",
    "\n",
    "    # Extract Raw Audio from multi-channel Wav File\n",
    "    signal = spf.readframes(nFrames*nChannels)\n",
    "    spf.close()\n",
    "    channels = interpret_wav(signal, nFrames, nChannels, ampWidth, True)\n",
    "\n",
    "    # get window size\n",
    "    # from http://dsp.stackexchange.com/questions/9966/what-is-the-cut-off-frequency-of-a-moving-average-filter\n",
    "    freqRatio = (cutOffFrequency/sampleRate)\n",
    "    N = int(math.sqrt(0.196196 + freqRatio**2)/freqRatio)\n",
    "\n",
    "    # Use moviung average (only on first channel)\n",
    "    filtered = running_mean(channels[0], N).astype(channels.dtype)\n",
    "\n",
    "    wav_file = wave.open(outname, \"w\")\n",
    "    wav_file.setparams((1, ampWidth, sampleRate, nFrames, spf.getcomptype(), spf.getcompname()))\n",
    "    wav_file.writeframes(filtered.tobytes('C'))\n",
    "    wav_file.close()\n",
    "\n",
    "    \n",
    "import noisereduce as nr\n",
    "# load data\n",
    "rate, data = wavfile.read(\"filtered.wav\")\n",
    "# select section of data that is noise\n",
    "noisy_part = data[:-1]\n",
    "# perform noise reduction\n",
    "reduced_noise = nr.reduce_noise(audio_clip=data, noise_clip=noisy_part, verbose=True)\n",
    "\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "harvard = sr.AudioFile('filtered.wav')\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "    type(audio)\n",
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
